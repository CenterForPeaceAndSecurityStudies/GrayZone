---
title: "Appendix"
author: "Author names redacted"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: yes
    toc_depth: '5'
  html_notebook:
    fig_height: 8
    fig_width: 12
    number_sections: yes
    theme: flatly
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: yes
  word_document:
    toc: no
    toc_depth: '5'
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '5'
editor_options:
  chunk_output_type: inline
header-includes: 
  - \usepackage{tikz}
  - \usepackage{pgfplots}
bibliography: GrayZone.json
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, error = FALSE, message = FALSE)
library(magrittr)
library(ggplot2)
```

This appendix accompanies the paper "After Deterrence: Explaining Conflict Short of War". It provides supplemental information concerning proofs for the formal model, the dataset of Russian gray zone campaigns introduced in the paper, and robustness checks and alternate specifications for the statistical model.

# Formal Model
## Formal statement of assumptions
First, we express the assumption that the kinks in the P function are never activated in equilibrium. Letting $\tilde{g_{C}}$ and $\tilde{g_{D}}$ denote the optimal levels selected by C and D conditional on the actors selecting into gray zone conflict (these are defined below), when Assumption 1 holds, the ``min-max'' statements in the $P$ function will never be relevant to analysis.
 
\textbf{\textit{Assumption 1}}\textit{: In equilibrium, $\rho_{0}<P(\tilde{g_{C}},\tilde{g_{D}})<1$.}\footnote{Based on the optimal $\tilde{g_{C}}$ and $\tilde{g_{D}}$ (solved below), this condition amounts to $\frac{\theta}{2\beta_{C}}-\frac{1}{2\beta_{D}}>0$ and $\frac{1}{\beta_{D}}-\frac{\theta}{\beta_{C}}-2\rho_{0}+2>0$ if $\frac{\theta}{2\beta_{C}}<\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$, and $\rho_{W}-\rho_{0}+\kappa_{D}-\frac{1}{4\beta_{D}}>0$ and $\frac{1}{\beta_{D}}-4\left(\kappa_{D}-1+\rho_{W}\right)>0$ if $\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\leq\frac{\theta}{2\beta_{C}}$.}
 
Second, we express the assumption that if C's resolve increases, C becomes more willing to go to war over using gray zone conflict. As some intuition, conditional on gray zone conflict occurring, C selects one of two values for $r$. For the first value, the selected $r$ will be the largest possible $r$ that is tailored to keep D from going to war. I call this $\hat{g_{C}}$. For the second value, the selected $g_{C}$ will be based on C's own resolve and represents the solution to C's internal optimization problem or C's internal efficiency. I call this $\check{g_{C}}$.\footnote{Intuitively, $\tilde{g_{C}}$ is defined by $\tilde{g_{C}}=min\{\hat{g_{C}},\check{g_{C}}\}$.} For C's utility from war to be increasing in $\theta$ at a faster rate than the utility from gray zone conflict, we must consider both values of $g_{C}$.

\textbf{\textit{ Assumption 2:}}\textit{ The following must hold: $\frac{d}{d\theta}\left[\theta\rho_{W}-\kappa_{D}-\left(\theta P(\hat{g_{C}},\tilde{g_{D}})-\beta(\tilde{g_{D}})^{2}\right)\right]>0$ }

\textit{ and $\frac{d}{d\theta}\left[\theta\rho_{W}-\kappa_{D}-\left(\theta P(\check{g_{C}},\tilde{g_{D}})-\beta(\tilde{g_{D}})^{2}\right)\right]>0$.}\footnote{Based on the optimal $\hat{g_{C}}$, $\check{g_{C}}$, and $\tilde{g_{D}}$ (solved below), this condition amounts to $\rho_{W}-\rho_{0}+\frac{1}{2\beta_{D}}-\frac{\theta}{2\beta_{C}}>0$ and $-\kappa_{D}+\frac{1}{4\beta_{D}}>0$. }

## Proving Proposition 1

### Equilibrium Intuition
Outside of gray zone conflict, C will prefer the status quo to initially going to war when 
  \begin{align*}
  \theta\rho_{0}\geq & \theta\rho_{W}-\kappa_{C}
  \end{align*}
or 
  \begin{align*}
  \theta\leq & \frac{\kappa_{C}}{\rho_{W}-\rho_{0}}.
  \end{align*}

Here I discuss the intuition of the equilibrium in the paper. Assume for now that C is optimally selecting a $g_{C}^{*}$ such that the game ends in gray zone conflict (in other words assume that $w_{R}^{*}=0$ and $g_{C}^{*}\geq0$). Also assume that D selects an optimal $g_{D}^{*}$ such that $g_{D}^{*}\leq g_{C}^{*}$ (this will be borne out by Assumption 1). D selects $g_{D}^{*}$ characterized by 
  \begin{align*}
  g_{D}^{*}\in & argmax_{g_{D}\geq0}\left\{ 1-\rho_{0}-g_{C}+g_{D}-\beta_{D}g_{D}^{2}\right\}.
  \end{align*}
I take first-order conditions with respect to $g_{D}$ and solve the expression above to identify the optimal level of D's gray zone response $g_{D}^{*}$. This unique value is 
  \begin{align*}
  g_{D}^{*}= & \frac{1}{2\beta_{D}}.
  \end{align*}

Using the expression for $g_{D}^{*}$, D's utility in terms of the selected $g_{C}^{*}$ is $U_{D}=1-\rho_{0}-g_{C}^{*}+\frac{1}{4\beta_{D}}$.

I can then begin considering C's utility. There are two things to consider. First, it could be that C will select an optimal $g_{C}^{*}$ that is constrained by D's willingness to go to war. Essentially, if $g_{C}>\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$, then D's utility from war is greater than D's utility from gray zone conflict; thus, if C wants to remain in gray zone conflict and will be constrained by D's deterrent threat, C will select $\hat{g_{C}}$, where $\hat{g_{C}}$ is the greatest $g_{C}$ that would make D indifferent between gray zone conflict and war, or
  \begin{align*}
  \hat{g_{C}} & =\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}.
  \end{align*}
Second C may select an optimal $g_{C}^{*}$ that is constrained by their own internal costs. When this is the case, C will select $\check{g_{C}}$, defined by the optimization 
  \begin{align*}
  \check{g_{C}}\in & argmax_{g_{C}\geq0}\left\{ \theta\left(\rho_{0}+g_{C}-\frac{1}{2\beta_{D}}\right)-\beta_{C}g_{C}\right\},
  \end{align*}
which yields 
  \begin{align*}
  \check{g_{C}} & =\frac{\theta}{2\beta_{C}}.
  \end{align*}
Before discussing the true behavior, I want to highlight two things that do not happen. First, note that C will never select an $g_{C}$ that provokes D to go to war in the final stage, because this is strictly worse than initially going to war. Second, note that C will never select into gray zone conflict (i.e. set $w_{R}=0$ and $g_{C}^{*}>0$) if $g_{D}^{*}$ as defined above is greater than $g_{C}^{*}$ because C could do strictly better not paying the costs of war and selecting into the status quo ($g_{C}^{*}=0$).

With this is place, I can say that if C optimally selects into gray zone conflict, C will select $g_{C}^{*}=\tilde{g_{C}}$, where 
  \begin{align*}
  \tilde{g_{C}}= & min\left\{ \hat{g_{C}},\check{g_{C}}\right\} .
  \end{align*}
I've characterized what happens withing gray zone conflict. I now need to describe how the game optimally plays out across the possibility of selecting into the status quo, war (at the onset; $w_{A}=1$), or gray zone conflict. Because C moves first, this is ultimately C's choice. I can calculate C's decision within the two cases of gray zone conflict:

First, I consider the case when $\frac{\theta}{2\beta_{C}}\geq\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$. This condition implies that the selected gray zone conflict will be constrained by D's deterrent threat and not C's internal costs. So, if C selects into gray zone conflict, C will select $g_{C}^{*}=\hat{g_{C}}=\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$. I can then express C's behavior in terms of $\theta$. C prefers the status quo to gray zone conflict when 
  \begin{align*}
  \theta\rho_{0}\geq & \theta\left(\rho_{W}+\kappa_{D}-\frac{1}{4\beta_{D}}\right)-\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}
  \end{align*}
or 
  \begin{align*}
  \theta\leq & \frac{\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}}{\left(\rho_{W}-\rho_{0}+\kappa_{D}-\frac{1}{4\beta_{D}}\right)}.
  \end{align*}
Note that the above derivation relies on $\rho_{W}-\rho_{0}+\kappa_{D}-\frac{1}{4\beta_{D}}>0$, lest the inequality sign would flip. This is assumed by Assumption 1.
 
Next, C prefers war to gray zone conflict when
  \begin{align*}
  \theta\rho_{W}-\kappa_{C}> & \theta\left(\rho_{W}+\kappa_{D}-\frac{1}{4\beta_{D}}\right)-\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}
  \end{align*}
or 
  \begin{align*}
  \theta> & \frac{\kappa_{C}-\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}}{\frac{1}{4\beta_{D}}-\kappa_{D}}.
  \end{align*}
Note that the above derivation relies on $\frac{1}{4\beta_{D}}-\kappa_{D}>0$, lest the inequality sign would flip. this is assumed by Assumption 2.

Next, I assume $\frac{\theta}{2\beta_{C}}<\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$. This condition implies that the selected gray zone conflict will be constrained by C's internal costs and not D's deterrent threat. So, if C selects into gray zone conflict, C will select $g_{C}^{*}=\check{g_{C}}=\frac{\theta}{2\beta_{C}}$. I can then express C's behavior in terms of $\theta$. C prefers the status quo to gray zone conflict when
  \begin{align*}
  \theta\rho_{0}\geq & \theta\rho_{0}+\frac{\theta^{2}}{4\beta_{C}}-\frac{\theta}{2\beta_{D}}
  \end{align*}
or 
  \begin{align*}
  0\geq & \theta\left(\frac{\theta}{4\beta_{C}}-\frac{1}{2\beta_{D}}\right).
  \end{align*}

Next, C prefers war to gray zone conflict when 
  \begin{align*}
  \theta\rho_{W}-\kappa_{C}> & \theta\rho_{0}+\frac{\theta^{2}}{4\beta_{C}}-\frac{\theta}{2\beta_{D}}
  \end{align*}
or 
  \begin{align*}
  \theta> & \frac{\kappa_{C}}{\rho_{W}-\rho_{0}-\frac{\theta}{4\beta_{C}}+\frac{1}{2\beta_{D}}}.
  \end{align*}
Note that the above derivation relies on $\rho_{W}-\rho_{0}-\frac{\theta}{4\beta_{C}}+\frac{1}{2\beta_{D}}>0$, lest the inequality sign would flip. This is implied by Assumption 2.

With all of this defined, we can characterize C's strategy in terms of $\theta$; as $\theta$ increases, C prefers more degrees of conflict (i.e. larger $g_{C}^{*}$'s or war) to get what they want.

### Equilibrium Behavior
Proposition 1A and the text below contains a more complete discussion on the equilibrium behavior characterized in Proposition 1.

\textbf{\textit{Proposition 1A:}}\textit{ In equilibrium, the game will play out in the following manner.}

\textit{Case 1, $\frac{\theta}{2\beta_{C}}\geq\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$:} 
  \begin{itemize}
  \item \textit{1.A. If $\theta\leq\frac{\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}}{\left(\rho_{W}-\rho_{0}+\kappa_{D}-\frac{1}{4\beta_{D}}\right)}$ and $\theta\leq\frac{\kappa_{C}}{\rho_{W}-\rho_{0}}$, then C accepts the status quo. C selects $w_{R}^{*}=0$ and $g_{C}^{*}=0$, and D selects $w_{D}^{*}=0$ and $g_{D}^{*}=0$. Payoffs are $U_{D}=1-\rho_{0}$ and $U_{C}=\theta\rho_{0}.$} 
  \item \textit{1.B. If $\theta>\frac{\kappa_{C}-\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}}{\frac{1}{4\beta_{D}}-\kappa_{D}}$ and $\theta>\frac{\kappa_{C}}{\rho_{W}-\rho_{0}}$, then C declares war. C selects $w_{R}^{*}=1$, and payoffs are $U_{D}=1-\rho_{W}-\kappa_{D}$ and $U_{C}=\theta\rho_{W}-\kappa_{A}$.} 
  \item \textit{1.C. Otherwise, the game end in gray zone conflict where }C's\textit{ limited challenge is constrained by D's deterrent threat. C selects $w_{R}^{*}=0$ and $g_{C}^{*}=\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$, and D selects $w_{D}^{*}=0$ and $g_{D}^{*}=\frac{1}{2\beta_{D}}$. Payoffs are $U_{D}=1-\rho_{W}-\kappa_{D}$ and $U_{C}=\theta\left(\rho_{W}+\kappa_{D}-\frac{1}{4\beta_{D}}\right)-\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}.$} 
  \end{itemize}

\textit{Case 2, $\frac{\theta}{2\beta_{C}}<\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$:} 
  \begin{itemize}
  \item \textit{2.A. If $\theta\leq\frac{2\beta_{C}}{\beta_{D}}$ and $\theta\leq\frac{\kappa_{C}}{\rho_{W}-\rho_{0}}$, then C accepts the status quo. C selects $w_{R}^{*}=0$ and $g_{C}^{*}=0$, and D selects $w_{D}^{*}=0$ and $g_{D}^{*}=0$. Payoffs are $U_{D}=1-\rho_{0}$ and $U_{C}=\theta\rho_{0}.$} 
  \item \textit{2.B. If $\theta>\frac{\kappa_{C}}{\rho_{W}-\rho_{0}-\frac{\theta}{4\beta_{C}}+\frac{1}{2\beta_{D}}}$ and $\theta>\frac{\kappa_{C}}{\rho_{W}-\rho_{0}}$, then C declares war. C sets $w_{R}^{*}=1$. Payoffs are $U_{D}=1-\rho_{W}-\kappa_{D}$ and $U_{C}=\theta\rho_{W}-\kappa_{A}$.} 
  \item \textit{2.C. Otherwise, the game will end in gray zone conflict where }C's\textit{ limited challenge is constrained by }C's\textit{ internal efficiency. C selects $w_{R}^{*}=0$ and $g_{C}^{*}=\frac{\theta}{2\beta_{C}}$, and D selects $w_{D}^{*}=0$ and $g_{D}^{*}=\frac{1}{2\beta_{D}}$. Payoffs are $U_{D}=1-\rho_{0}-\frac{\theta}{2\beta_{C}}+\frac{1}{4\beta_{D}},$ and $U_{C}=\theta\rho_{0}+\frac{\theta^{2}}{4\beta_{C}}-\frac{\theta}{2\beta_{D}}.$} 
  \end{itemize}

Working backwards, D will declare war for all $g_{C}>\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$. If $g_{C}\leq\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$, D will select $g_{D}=min\left\{ \frac{1}{2\beta_{D}},g_{C}\right\}$. When $g_{D}=\frac{1}{2\beta_{D}}$, D is selecting their optimal level of gray zone response based on their internal optimization. When $g_{D}=g_{C}$, it implies that D would be willing to select a greater gray zone response, but does not need to, essentially driving the political impact of C's limited challenges back to zero (at cost).

## Observation 1 Discussion
Assume for now the parameters are such that the Case 1.C. conditions hold, and consider what happens when $\kappa_{D}$ decreases. Because here C selects the greatest level of limited challenges that will not provoke D to war, C's selected $g_{C}^{*}$ is a decreasing function of $\kappa_{D}$; therefore, because $g_{D}^{*}$ is fixed, the final extent of gray zone conflict will be less. Of course, the analysis does not stop there. Improvements in D's willingness to go to war constrain how useful gray zone conflict is to R, and, within case 1.C., C's utility is decreasing in $-\kappa_{D}$.\footnote{This follows from $\frac{d}{d\kappa_{D}}U_{D}=\theta-2\beta_{C}\left[\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right]>0$, as determined by the conditions for Case 1 to hold.} Thus, if $\kappa_{D}$ becomes small enough, C will leave gray zone conflict and instead select into either accepting the status quo (entering into case 1A) or going to war (entering into Case 1B). Additionally, it is worthwhile noting that as $\kappa_{D}$ decreases, the condition that selects into Case 1 (over Case 2) has more slack, implying that improvements in D's willingness to go to war will keep D in within Case 1.

Now assume the parameters are such that the Case 2.C. conditions hold, and consider what happens when $\kappa_{D}$ decreases. Note that this will not change the selected $g_{C}^{*}$ here, but it could break the inequality $\frac{\theta}{2\beta_{C}}<\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$ that determines whether the equilibrium is defined in Case 1 or Case 2. thus, for a small enough $\kappa_{D}$, the conditions for Case 2 will break and the conditions for Case 1 will hold. When this happens, either the selected $g_{C}^{*}$ is increasing in $\kappa_{D}$ (Case 1.C.) or gray zone conflict is not selected (Case 1.A. or 1.B.).
 
## Extension 1: Endogenous $\beta_{D}$
In the model in the paper, I treated D's gray zone efficiency $\beta_{D}$ as exogenous. In some special cases or under some conditions, this may be too strong an assumption. In this section, I characterize an equilibrium for the game when D can have complete flexibility in selecting some $\beta_{D}\geq\underline{\beta_{D}}>0$, where $\beta_{D}$ cannot equal zero lest D's costs from their gray zone response will be undefined.\footnote{For ease, I will assume that all parameters imply that the selected equilibrium is such that the selected $\beta_{D}^{*}$ is strictly greater than $\underline{\beta_{D}}$.} The key take away from this extension is that if $\beta_{D}$ is endogenous (and its selection costless), then D's selection of $\beta_{D}^{*}$ will be arbitrated by two properties. As the first property, it matters whether C prefers war to the status quo (formally, if C is type $\theta>\frac{\kappa_{D}}{\rho_{W}-\rho_{0}}$), or C prefers the status quo to war ($\theta\leq\frac{\kappa_{D}}{\rho_{W}-\rho_{0}}$). When C prefers the status quo to war, then D is in a position where D can, by selecting a low enough $\beta_{D}$, influence C to stop undertaking limited challenges and select into the status quo. Intuitively, when D is very good at gray zone conflict, D would select a high $g_{D}^{*}$, which makes gray zone conflict less productive for C. But, when C prefers war to the status quo, then D could pressure C to stop undertaking limited challenges, but this will result in C going to war with D.

As the second property, D's decision will also be arbitrated by whether D can select a gray zone efficiency $\beta_{D}^{*}$ that pushes C into a level of gray zone conflict where the deterrent threat does not bind. Recall that if C optimally conducts gray zone conflict, C selects $g_{C}^{*}=min\{\hat{g_{C}},\check{g_{C}}\}$, implying that C will either select an optimal $g_{C}^{*}=\check{g_{C}}=\frac{\theta}{2\beta_{C}}$ based on their own internal cost-benefit analysis, or select an optimal $g_{C}^{*}=\hat{g_{C}}=\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$ tailored to make D indifferent between war and gray zone conflict (where the deterrent threat binds), with C ultimately choosing the smaller of the two. This means that if D can select a small enough $\beta_{D}$ so that $\check{g_{C}}<\hat{g_{C}}$, then C will selecting a level of limited challenge that is below the point that would make D indifferent between war and gray zone conflict, thus granting D some surplus.

The above two properties interact. Based on Assumptions 1 and 2, D will always prefer the status quo to gray zone conflict where the deterrent threat doesn't bind, and gray zone conflict where the deterrent threat doesn't bind to gray zone conflict where the deterrent threat does bind or war. Proposition A identifies how D selects $\beta_{D}^{*}$ in one possible equilibrium. Note that this is not the only possible equilibrium.\footnote{Consider the equilibrium space for the range of $\theta$ where the selected $\beta_{D}$ will either push C into war or gray zone conflict where the deterrent threat binds. In the figure below, this is the far right region of the graph. Here D can select any $\beta_{D}$ and it will grant D the same final expected utility of their wartime utility.}

\textbf{\textit{Proposition A.}}\textit{ As one equilibrium, in the game with endogenous $\beta_{D}$, D will select the following levels of $\beta_{D}^{*}$:}
 
\textit{Case 1: $\theta\leq\frac{\kappa_{D}}{\rho_{W}-\rho_{0}}$:} 
  \begin{itemize}
  \item \textit{1.A. I define $\tilde{\beta_{D}}$ as $\theta=\frac{2\beta_{C}}{\tilde{\beta_{D}}}$ . So long that $\frac{\theta}{2\beta_{C}}<\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\tilde{\beta_{D}}}$, then D selects $\beta_{D}^{*}=\tilde{\beta_{D}}$. The game will proceed as defined in Proposition 1, Case 2.A., where the final outcome is the status quo.} 
  \item \textit{1.B. Otherwise, D selects $\beta_{D}^{*}=\hat{\beta_{D}}$, here $\hat{\beta_{D}}$ is defined implicitly as $\theta=\frac{\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\hat{\beta_{D}}}\right)^{2}}{\left(\rho_{W}-\rho_{0}+\kappa_{D}-\frac{1}{4\hat{\beta_{D}}}\right)}$ (also note from earlier assumptions $\hat{\beta}_{D}>0$). The game will proceed as defined in Proposition 1, Case 1.A., where the final out come is the status quo.} 
  \end{itemize}

\textit{Case 2: $\theta>\frac{\kappa_{D}}{\rho_{W}-\rho_{0}}$} 
  \begin{itemize}
  \item \textit{2.A. I define $\check{\beta_{D}}$ implicitly as $\theta=\frac{\kappa_{C}}{\left(\rho_{W}-\rho_{0}-\frac{\theta}{4\beta_{C}}+\frac{1}{2\check{\beta_{D}}}\right)}$. So long that $\frac{\theta}{2\beta_{C}}<\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\check{\beta_{D}}}$, then D selects $\beta_{D}^{*}=\check{\beta_{D}}$. The game will proceed as defined in Proposition 1, Case 2.C., where the final outcome is gray zone conflict where C is not bound by D's deterrent threat.} 
  \item \textit{2.B. Otherwise, D selects $\beta_{D}^{*}=\dot{\beta_{D}}$, here $\dot{\beta_{D}}$ is defined implicitly as $\theta=\frac{\kappa_{C}-\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\dot{\beta_{D}}}\right)^{2}}{-\kappa_{D}+\frac{1}{4\dot{\beta_{D}}}}$. The game will proceed as defined in Proposition 1, Case 1.C., where the final outcome is gray zone conflict where is not bound by D's deterrent threat.} 
  \end{itemize}
As one example of how this one equilibrium plays out, I adapt Figure 4 in the text. Now the solid black lines denote the selected levels of $\beta_{D}^{*}$ (with $1/\beta_{D}$ plotted so that greater y-axis values represent greater gray zone efficiencies for D), and the dotted lines separate equilibrium spaces.

\begin{figure}
\begin{tikzpicture} 
\small
\begin{axis}[%
width=5.5in,
height=3.5in,
at={(1.011in,0.642in)},
scale only axis,
xmin=1.285,
xmax=1.4,
xtick={1.285, 1.315, 1.366,1.4},
xticklabels={{1.285},{$\theta=\frac{\kappa_R}{\rho_W-\rho_0}$},{$\theta=2\beta_R(\rho_{W}$-$\rho_{0}$+$\kappa_{D}$+$\frac{1}{4\check{\beta_D}})$},{1.4}},
%{\shortstack{$\frac{\theta}{2\beta}=(\rho_{W}-$\\$\rho_{0}+\kappa_{D}+\frac{d}{4})$}}
xlabel style={font=\color{white!15!black},align=center},
xlabel={\textbf{C's Resolve Increasing $\rightarrow$} \\ $\theta$ (plotted) Increasing $\rightarrow$ },
ymin=0.635,
ymax=0.67,
ytick={0.635, 0.67},
yticklabels={{0.635},{0.66}},
ylabel style={font=\color{white!15!black}, align=center},
ylabel={\textbf{D's Optimal Gray Zone Efficiency Increasing $\rightarrow$} \\ $\frac{1}{\beta_D^*}$ (plotted) Increasing $\rightarrow$},
axis background/.style={fill=white},
title style={font=\bfseries},
title={Equilibrium Behavior: C's Resolve and D's Gray Zone Efficiency},
]

%
 
\node[draw, align=center] at (1.3,0.66) {\footnotesize{\textit{R Accepts}} \\ \footnotesize{\textit{Status Quo}}};
\node[draw, align=center] at (1.32,0.645) {\footnotesize{\textit{R Selects Gray Zone,}} \\ \footnotesize{\textit{Internal Efficiency Binds}}}; 
\node[draw, align=center] at (1.383,0.642) {\footnotesize{\textit{R Selects Gray Zone,}} \\ \footnotesize{\textit{Deterrent Threat Binds}}}; 
\node[draw, align=center] at (1.36,0.662) {\footnotesize{\textit{R Selects War}}};  

%\node[draw, align=center] at (.1925,1.2) {\footnotesize{\textit{Gray Zone,}} \\ \footnotesize{\textit{Unconstrained}}}; 

%BEGIN DOTTED LINES

\addplot [color=white!55!black, dotted, line width=1.3pt, forget plot]
  table[row sep=crcr]{%
1.315 	0.6575\\
1.315	0.67\\
};


%\addplot [color=white!55!black, dotted, line width=1.3pt, forget plot]
 % table[row sep=crcr]{%
%1.315 	0.6575\\
%1.315	0.635\\
%};

%END DOTTED LINES

%WAR
%\addplot [color=black, line width=1.2pt]
%  table[row sep=crcr]{%
%1.315		0.6575\\
%1.315			0.69\\
%};

%GZ CONSTRAINTS
\addplot[color=white!55!black, dotted, line width=1.3pt, forget plot]
  table[row sep=crcr]{%
1.3575	0.635	\\
1.358	0.636	\\
1.3585	0.637	\\
1.359	0.638	\\
1.3595	0.639	\\
1.36	0.64	\\
1.3605	0.641	\\
1.361	0.642	\\
1.3615	0.643	\\
1.362	0.644	\\
1.3625	0.645	\\
1.363	0.646	\\
1.3635	0.647	\\
1.364	0.648	\\
1.3645	0.649	\\
1.365	0.65	\\
1.3655	0.651	\\
1.366	0.652	\\
};

%GZ INTERIOR PEACE
\addplot [color=black, line width=1.2pt, forget plot]
  table[row sep=crcr]{%
1.285	0.6425	\\
1.286	0.643	\\
1.287	0.6435	\\
1.288	0.644	\\
1.289	0.6445	\\
1.29	0.645	\\
1.291	0.6455	\\
1.292	0.646	\\
1.293	0.6465	\\
1.294	0.647	\\
1.295	0.6475	\\
1.296	0.648	\\
1.297	0.6485	\\
1.298	0.649	\\
1.299	0.6495	\\
1.3	0.65	\\
1.301	0.6505	\\
1.302	0.651	\\
1.303	0.6515	\\
1.304	0.652	\\
1.305	0.6525	\\
1.306	0.653	\\
1.307	0.6535	\\
1.308	0.654	\\
1.309	0.6545	\\
1.31	0.655	\\
1.311	0.6555	\\
1.312	0.656	\\
1.313	0.6565	\\
1.314	0.657	\\
1.315	0.6575	\\
1.3155	0.65775	\\
};

%GZ INTERIOR WAR
\addplot [color=black, line width=1.2pt, forget plot]
  table[row sep=crcr]{%
1.315	0.657804183	\\
1.316	0.657665653	\\
1.317	0.657528094	\\
1.318	0.657391502	\\
1.319	0.657255876	\\
1.32	0.657121212	\\
1.321	0.656987509	\\
1.322	0.656854766	\\
1.323	0.656722978	\\
1.324	0.656592145	\\
1.325	0.656462264	\\
1.326	0.656333333	\\
1.327	0.65620535	\\
1.328	0.656078313	\\
1.329	0.65595222	\\
1.33	0.655827068	\\
1.331	0.655702855	\\
1.332	0.65557958	\\
1.333	0.655457239	\\
1.334	0.655335832	\\
1.335	0.655215356	\\
1.336	0.655095808	\\
1.337	0.654977188	\\
1.338	0.654859492	\\
1.339	0.654742718	\\
1.34	0.654626866	\\
1.341	0.654511931	\\
1.342	0.654397914	\\
1.343	0.65428481	\\
1.344	0.654172619	\\
1.345	0.654061338	\\
1.346	0.653950966	\\
1.347	0.6538415	\\
1.348	0.653732938	\\
1.349	0.653625278	\\
1.35	0.653518519	\\
1.351	0.653412657	\\
1.352	0.653307692	\\
1.353	0.653203622	\\
1.354	0.653100443	\\
1.355	0.652998155	\\
1.356	0.652896755	\\
1.357	0.652796242	\\
1.358	0.652696613	\\
1.359	0.652597866	\\
1.36	0.6525	\\
1.361	0.652403012	\\
1.362	0.652306902	\\
1.363	0.652211665	\\
1.364	0.652117302	\\
1.365	0.65202381	\\
1.366	0.651931186	\\
};

%GZ External WAR
\addplot [color=black, line width=1.2pt, forget plot]
  table[row sep=crcr]{%
1.409290323	0.648	\\
1.408172501	0.6481	\\
1.40705556	0.6482	\\
1.405939499	0.6483	\\
1.404824316	0.6484	\\
1.40371001	0.6485	\\
1.402596581	0.6486	\\
1.401484027	0.6487	\\
1.400372347	0.6488	\\
1.399261541	0.6489	\\
1.398151606	0.649	\\
1.397042543	0.6491	\\
1.39593435	0.6492	\\
1.394827026	0.6493	\\
1.393720569	0.6494	\\
1.39261498	0.6495	\\
1.391510256	0.6496	\\
1.390406398	0.6497	\\
1.389303403	0.6498	\\
1.388201271	0.6499	\\
1.3871	0.65	\\
1.38599959	0.6501	\\
1.38490004	0.6502	\\
1.383801348	0.6503	\\
1.382703514	0.6504	\\
1.381606537	0.6505	\\
1.380510415	0.6506	\\
1.379415148	0.6507	\\
1.378320734	0.6508	\\
1.377227172	0.6509	\\
1.376134462	0.651	\\
1.375042603	0.6511	\\
1.373951592	0.6512	\\
1.372861431	0.6513	\\
1.371772116	0.6514	\\
1.370683648	0.6515	\\
1.369596025	0.6516	\\
1.368509247	0.6517	\\
1.367423312	0.6518	\\
1.36633822	0.6519	\\
1.365253968	0.652	\\
};

%   \node at (1.3,0.502)  [circle,scale=0.7,minimum size=0.5pt,draw,fill=black!100] {};
%   \node at (1.3,0.65)  [circle,scale=0.7,draw,fill=black!0] {};

\end{axis}
\end{tikzpicture}\vspace{0.8cm}

\caption{Extension 1: D's Optimal $d^{*}$}
\caption*{C's resolve $\theta$ and the inverse D's gray zone efficiency $\frac{1}{\beta_{D}}$ are plotted. The dotted lines separate different kinds of equilibrium play, and the dark black lines denote D's optimal selected $\beta_{D}$. The parameters are $\rho_{0}=0$, $\rho_{W}=0.5$, $\beta_{C}=1$, $\kappa_{C}=0.53$, and $\kappa_{D}=0.1$.}
\end{figure}

Moving left to right, for $\theta$ between $1.285$ and $\frac{\kappa_{C}}{\rho_{W}-\rho_{0}}$, D's optimal $\beta_{D}^{*}$ is described in Proposition A Case 1.A. As the outcome, C will optimally select into the status quo. For this selected $\beta_{D}^{*}$, C knows that C would face enough of a challenge in gray zone conflict to make competing there too costly. Thus within this region, D could select a low enough $\beta_{D}^{*}$ to compel C to forgo limited challenges and conflict, and stick to the status quo.

Moving right, for $\theta$ between $\frac{\kappa_{C}}{\rho_{W}-\rho_{0}}$ and $\ensuremath{2\beta_{C}(\rho_{W}-\ensuremath{\rho_{0}}+\kappa_{D}}+\frac{1}{4\check{\beta_{D}}})$, D's optimal $\beta_{D}^{*}$ is described in Proposition A Case 2.A. As the outcome, C will optimally select into gray zone conflict, but will be constrained by C's internal costs. For this selected $\beta_{D}^{*}$, D wants to challenge C in gray zone conflict (which a lower $\beta_{D}^{*}$ accomplishes), but does not want to push C into forgoing gray zone conflict, because within this region C prefers war to accepting the status quo. Thus here, D selects the $\beta_{D}^{*}$ where C selects into gray zone conflict and is not bound by the deterrent threat, because this gives D some surplus beyond what war or C selecting gray zone conflict and being bound by the deterrent threat produces.

Finally, for $\theta$ between $\ensuremath{2\beta_{C}(\rho_{W}-\ensuremath{\rho_{0}}+\kappa_{D}}+\frac{1}{4\check{\beta_{D}}})$ and $1.4$, D's optimal $\beta_{D}^{*}$ is described in Case 2.B. As the outcome, C will optimally select into gray zone conflict, and will be constrained by D's deterrent threat. Essentially here, D is in a bad situation. If D modifies $\beta_{D}^{*},$either C will adapt by selecting the new $g_{C}^{*}$ that makes D indifferent between war and gray zone conflict, or will go to war over the issue. Within this region, it does not matter what $\beta_{D}^{*}$ is selected, because C will always select an action that gives D their wartime utility.

## Extension 2: Probabilistic Escalation to War
A useful feature of the model above is that everything that occurs is deterministic. It is only if a state wants to go to war or wants to enter gray zone conflict does it actually happen. However, this may not perfectly represent reality. Perhaps in some cases, one state behaving aggressively in lower-levels of conflict can create an incident that necessitates an escalation to higher levels of conflict. To speak to this issue, we introduce the possibility of probabilistic escalation out of gray zone conflict. Our results are substantively similar, but this change shifts some equilibrium properties. Intuitively, now gray zone conflict can probabilistically lead to C's worst outcome: where C invests in limited challenges, war happens, and C must pay the costs of limited challenges with the costs of war. Strategically, because here gray zone conflict is overall worse for R, C will be more willing to accept the status quo or go to war.

There are many possible ways to model this. For ease, we choose (in our opinion) the simplest way, which is that selecting $g_{C}>0$ introduces a $1-\zeta\in(0,1)$ likelihood of an escalation to war. Thus, when C selects $g_{C}>0$, C's new expected utility is 
  \begin{align*}
  U_{C}= & \theta\left(\zeta P(g_{C},g_{D})+(1-\zeta)\rho_{W}\right)-(1-\zeta)\kappa_{C}-\beta_{C}g_{C}.
  \end{align*}
To offer some intuition, $g_{D}^{*}$, $\hat{g_{C}}$, $\check{g_{C}}$, and $\tilde{g_{C}}$ remain the same as it was in the model in the text (as defined in Proposition 1). However, the cut-points that distinguish C's decision to enter into the status quo, gray zone conflict, or war change slightly; overall, the key take-away is that considering probabilistic escalation makes gray zone conflict less appealing relative to the status quo and war.

I express equilibrium behavior in Proposition B. Then below, I derive the new cut-points, Additionally in the derivations, I discuss how the new cut-points imply that gray zone conflict is less appealing and fewer types $\theta$ will select into it relative to the game without a probabilistic likelihood of escalation to war from gray zone conflict.

\textbf{\textit{Proposition B:}}\textit{ In equilibrium, the game with a $1-\zeta$ chance of escalation out of gray zone conflict to war will play out in the following manner.}

\textit{Case 1, $\frac{\theta}{2\beta_{C}}\geq\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$:} 
  \begin{itemize}
  \item \textit{1.A. If $\theta\leq\frac{(1-\zeta)\kappa_{C}+\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}}{(1-\zeta)(\rho_{W}-\rho_{0})+\zeta\left(\rho_{W}-\rho_{0}+\kappa_{D}-\frac{1}{4\beta_{D}}\right)}$ and $\theta\leq\frac{\kappa_{C}}{\rho_{W}-\rho_{0}}$, then C accepts the status quo. C selects $w_{R}^{*}=0$ and $g_{C}^{*}=0$, and D selects $w_{D}^{*}=0$ and $g_{D}^{*}=0$. } 
  \item \textit{1.B. If $\theta>\frac{\zeta\kappa_{C}-\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}}{\zeta\left(\frac{1}{4\beta_{D}}-\kappa_{D}\right)}$ and $\theta>\frac{\kappa_{C}}{\rho_{W}-\rho_{0}}$, then C declares war. C selects $w_{R}^{*}=1$.} 
  \item \textit{1.C. Otherwise, the game end in gray zone conflict where }C's\textit{ limited challenge is constrained by D's deterrent threat. C selects $w_{R}^{*}=0$ and $g_{C}^{*}=\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$, and (assuming the game does not probabilistically escalate to war) D selects $w_{D}^{*}=0$ and $g_{D}^{*}=\frac{1}{2\beta_{D}}$. } 
  \end{itemize}

\textit{Case 2, $\frac{\theta}{2\beta_{C}}<\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$:} 
  \begin{itemize}
  \item \textit{2.A. If $(1-\zeta)\kappa_{C}\geq\theta\left((1-\zeta)(\rho_{W}-\rho_{0})+\zeta\left(\frac{\theta}{2\beta_{C}}-\frac{1}{2\beta_{D}}\right)-\frac{\theta}{4\beta_{C}}\right)$ and $\theta\leq\frac{\kappa_{C}}{\rho_{W}-\rho_{0}}$, then C accepts the status quo. C selects $w_{R}^{*}=0$ and $g_{C}^{*}=0$, and D selects $w_{D}^{*}=0$ and $g_{D}^{*}=0$. } 
  \item \textit{2.B. If $\theta>\frac{\zeta\kappa_{C}}{\left(\zeta\left(\rho_{W}-\rho_{0}-\frac{\theta}{2\beta_{C}}+\frac{1}{2\beta_{D}}\right)+\frac{\theta}{4\beta_{C}}\right)}$ and $\theta>\frac{\kappa_{C}}{\rho_{W}-\rho_{0}}$, then C declares war. C sets $w_{R}^{*}=1$.}\footnote{\textit{While the right-hand-side of this condition is also increasing in $\theta$, by Assumption 2, the left-hand-side increases faster with increases in $\theta$.}}\textit{ } 
  \item \textit{2.C. Otherwise, the game will end in gray zone conflict where }C's\textit{ limited challenge is constrained by }C's\textit{ internal efficiency. C selects $w_{R}^{*}=0$ and $g_{C}^{*}=\frac{\theta}{2\beta_{C}}$, and (assuming the game does not probabilistically escalate to war) D selects $w_{D}^{*}=0$ and $g_{D}^{*}=\frac{1}{2\beta_{D}}$. } 
  \end{itemize}

### Equilibrium Intuition
First, we consider the case when $\frac{\theta}{2\beta_{C}}\geq\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$. This implies that C will select $g_{C}^{*}=\hat{g_{C}}=\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$. We can then express C's behavior in terms of $\theta$. C prefers the status quo to gray zone conflict when 
  \begin{align*}
  \theta\rho_{0}\geq & \theta\left(\zeta\left(\rho_{W}+\kappa_{D}-\frac{1}{4\beta_{D}}\right)+(1-\zeta)\rho_{W}\right)-(1-\zeta)\kappa_{C}-\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}
  \end{align*}
  or 
  \begin{align*}
  \frac{\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}}{\zeta\left(\rho_{W}-\rho_{0}+\kappa_{D}-\frac{1}{4\beta_{D}}\right)}+\frac{(1-\zeta)(\theta\rho_{0}-\theta\rho_{W}+\kappa_{C})}{\zeta\left(\rho_{W}-\rho_{0}+\kappa_{D}-\frac{1}{4\beta_{D}}\right)}\geq & \theta.
  \end{align*}
Note that the inequality sign does not flip because, by Assumption 1, $\rho_{W}-\rho_{0}+\kappa_{D}-\frac{1}{4\beta_{D}}>0$. I am able to say that $\frac{\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}}{\zeta\left(\rho_{W}-\rho_{0}+\kappa_{D}-\frac{1}{4\beta_{D}}\right)}>\frac{\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}}{\left(\rho_{W}-\rho_{0}+\kappa_{D}-\frac{1}{4\beta_{D}}\right)}$ because $\zeta\in(0,1)$. Furthermore, this constraint (on when the status quo is preferred to gray zone conflict) matters only when C prefers the status quo to war, or when $\theta\rho_{0}-\theta\rho_{W}+\kappa_{C}\geq0$; this condition implies $\frac{(1-\zeta)(\theta\rho_{0}-\theta\rho_{W}+\kappa_{C})}{\zeta\left(\rho_{W}-\rho_{0}+\kappa_{D}-\frac{1}{4\beta_{D}}\right)}\geq0$, which means $\frac{\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}}{\zeta\left(\rho_{W}-\rho_{0}+\kappa_{D}-\frac{1}{4\beta_{D}}\right)}+\frac{(1-\zeta)(\theta\rho_{0}-\theta\rho_{W}+\kappa_{C})}{\zeta\left(\rho_{W}-\rho_{0}+\kappa_{D}-\frac{1}{4\beta_{D}}\right)}>\frac{\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}}{\left(\rho_{W}-\rho_{0}+\kappa_{D}-\frac{1}{4\beta_{D}}\right)}$, which in turn implies that there are more C's with some resolve $\theta$ that will select into the status quo in the game here relative to the game in the text without probabilistic escalation.

Next, C prefers war to gray zone conflict when
  \begin{align*}
  \theta\rho_{W}-\kappa_{C}> & \theta\left(\zeta\left(\rho_{W}+\kappa_{D}-\frac{1}{4\beta_{D}}\right)+(1-\zeta)\rho_{W}\right)-(1-\zeta)\kappa_{C}-\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}
  \end{align*}
or 
  \begin{align*}
  \theta> & \frac{\zeta\kappa_{C}-\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}}{\zeta\left(\frac{1}{4\beta_{D}}-\kappa_{D}\right)}.
  \end{align*}

Note that based on Assumption 2 (as is written: that $\frac{1}{4\beta_{D}}-\kappa_{D}>0$), the above sign does not flip. I can say that $\zeta\kappa_{C}-\zeta\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}>\zeta\kappa_{C}-\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}$. This implies that
  \begin{align*}
  \frac{\kappa_{C}-\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}}{\frac{1}{4\beta_{D}}-\kappa_{D}}=\frac{\zeta\kappa_{C}-\zeta\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}}{\zeta\left(\frac{1}{4\beta_{D}}-\kappa_{D}\right)} & >\frac{\zeta\kappa_{C}-\beta_{C}\left(\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}\right)^{2}}{\zeta\left(\frac{1}{4\beta_{D}}-\kappa_{D}\right)}.
  \end{align*}

In other words, there are more C's with some resolve $\theta$ that will select into war in the game here relative to the game without probabilistic escalation.

Next, I assume $\frac{\theta}{2\beta_{C}}<\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$. This condition implies that the selected gray zone conflict will be constrained by C's internal costs and not D's deterrent threat. So, if C selects into gray zone conflict, C will select $g_{C}^{*}=\check{g_{C}}=\frac{\theta}{2\beta_{C}}$. I can then express C's behavior in terms of $\theta$. C prefers the status quo to gray zone conflict when 
  \begin{align*}
  \theta\rho_{0}\geq & \theta\left(\zeta\left(\rho_{0}+\frac{\theta}{2\beta_{C}}-\frac{1}{2\beta_{D}}\right)+(1-\zeta)\left(\rho_{W}\right)\right)-(1-\zeta)\kappa_{C}-\frac{\theta^{2}}{4\beta_{C}}
  \end{align*}
  or 
  \begin{align*}
  (1-\zeta)\kappa_{C}\geq & \theta\left((1-\zeta)(\rho_{W}-\rho_{0})+\zeta\left(\frac{\theta}{2\beta_{C}}-\frac{1}{2\beta_{D}}\right)-\frac{\theta}{4\beta_{C}}\right).
  \end{align*}

To speak to this inequality, we will need to consider a few different cases here.

First, it could be possible that $\left((1-\zeta)(\rho_{W}-\rho_{0})+\zeta\left(\frac{\theta}{2\beta_{C}}-\frac{1}{2\beta_{D}}\right)-\frac{\theta}{4\beta_{C}}\right)\leq0$. When this is the case, then C would never want to select into gray zone conflict as doing so would always be strictly worse for R.

Next, consider when $\left((1-\zeta)(\rho_{W}-\rho_{0})+\zeta\left(\frac{\theta}{2\beta_{C}}-\frac{1}{2\beta_{D}}\right)-\frac{\theta}{4\beta_{C}}\right)>0$ and $(1-\zeta)(\theta\rho_{W}-\theta\rho_{0}-\kappa_{C})>0$. In this case, C's wartime payoff $\theta\rho_{W}-\kappa_{C}$ is greater than C's status quo payoff, meaning that C would never select into the status quo over selecting into war, meaning this constraint would never be activated.

Finally, consider when $\left((1-\zeta)(\rho_{W}-\rho_{0})+\zeta\left(\frac{\theta}{2\beta_{C}}-\frac{1}{2\beta_{D}}\right)-\frac{\theta}{4\beta_{C}}\right)>0$ and $(1-\zeta)(\theta\rho_{W}-\theta\rho_{0}-\kappa_{C})<0$. I can re-write the above as 
  \begin{align*}
  0\geq & \theta\left(\zeta\left(\frac{\theta}{2\beta_{C}}-\frac{1}{2\beta_{D}}\right)-\frac{\theta}{4\beta_{C}}\right)+(1-\zeta)(\theta\rho_{W}-\theta\rho_{0}-\kappa_{C})
  \end{align*}
Where note that $\frac{\theta}{4\beta_{C}}-\frac{1}{2\beta_{D}}=\frac{\theta}{2\beta_{C}}-\frac{1}{2\beta_{D}}-\frac{\theta}{4\beta_{C}}>\zeta\left(\frac{\theta}{2\beta_{C}}-\frac{1}{2\beta_{D}}\right)-\frac{\theta}{4\beta_{C}}$, where the inequality holds by Assumption 1. Altogether, this means that $\text{\ensuremath{\theta\left(\frac{\theta}{4\beta_{C}}-\frac{1}{2\beta_{D}}\right)}}>\theta\left(\zeta\left(\frac{\theta}{2\beta_{C}}-\frac{1}{2\beta_{D}}\right)-\frac{\theta}{4\beta_{C}}\right)+(1-\zeta)(\theta\rho_{W}-\theta\rho_{0}-\kappa_{C})$. This implies that there are more C's with some resolve $\theta$ that will select into the status quo in the game here relative to the game without probabilistic escalation.

Finally, assuming $\frac{\theta}{2\beta_{C}}<\rho_{W}-\rho_{0}+\kappa_{D}+\frac{1}{4\beta_{D}}$, C prefers war to gray zone conflict when 
  \begin{align*}
  \theta\rho_{W}-\kappa_{C}> & \theta\left(\zeta\left(\rho_{0}+\frac{\theta}{2\beta_{C}}-\frac{1}{2\beta_{D}}\right)+(1-\zeta)\left(\rho_{W}\right)\right)-(1-\zeta)\kappa_{C}-\frac{\theta^{2}}{4\beta_{C}}
  \end{align*}
or 
  \begin{align*}
  \theta> & \frac{\zeta\kappa_{C}}{\left(\zeta\left(\rho_{W}-\rho_{0}-\frac{\theta}{2\beta_{C}}+\frac{1}{2\beta_{D}}\right)+\frac{\theta}{4\beta_{C}}\right)}.
  \end{align*}
Note the inequality sign does not slip because $\left(\rho_{W}-\rho_{0}-\frac{\theta}{2\beta_{C}}+\frac{1}{2\beta_{D}}\right)>0$. Furthermore, by that condition, $\zeta\left(\rho_{W}-\rho_{0}-\frac{\theta}{2\beta_{C}}+\frac{1}{2\beta_{D}}\right)+\frac{\theta}{4\beta_{C}}>\zeta\left(\rho_{W}-\rho_{0}-\frac{\theta}{2\beta_{C}}+\frac{1}{2\beta_{D}}\right)+\zeta\frac{\theta}{4\beta_{C}}$. Therefore $\frac{\kappa_{C}}{\left(\rho_{W}-\rho_{0}-\frac{\theta}{2\beta_{C}}+\frac{1}{2\beta_{D}}\right)+\frac{\theta}{4\beta_{C}}}>\frac{\zeta\kappa_{C}}{\zeta\left(\rho_{W}-\rho_{0}-\frac{\theta}{2\beta_{C}}+\frac{1}{2\beta_{D}}\right)+\frac{\theta}{4\beta_{C}}}$. This implies that there are more C's with some resolve $\theta$ that will select into war in the game here relative to the game without a random chance of escalation.

Finally, note that D's strategies in this game are unchanged from the game without probabilistic escalation.

# New data
The universe of cases was created by first identifying cases of Russian foreign interventions from 3 prior datasets; ICB, DCID, and REI. Code replicating those findings is provided in the appropriate RMarkdown files. These cases were then supplemented with additional cases of Russian interference the authors were able to identify.

## Coverage of current datasets
A comparison of what cases were covered in each individual dataset is provided here:

```{r xtable, results = 'asis', echo = FALSE}
# Read dataset
coverage <- readRDS(paste0(here::here(), '/data/coverage.rds'))

# Create venn diagram
col_keys = c("new", "icb", "dcid", "rei")
coverage_venn <- coverage[ , c('new', 'icb', 'dcid', 'rei')]
gplots::venn(coverage_venn)
```

## Consistency of current datasets

Aside from the cases covered, the intensity codings for current datasets are difficult to compare given their different scales. A more thorough analysis is provided in the appropriate R Markdown files, but a comparison of intensity codings in DCID (Valeriano and Maness) and REI (Way and Casey) is visualized here:

![](../paper/figures/map_prior-data.png)

The DCID data identifies the United States, United Kingdom, Poland and Ukraine as targets of the most severe Russian cyber operations. In the cases documented by REI, the most severe Russian attacks occurred against France, Austria, and Ukraine. Part of this discrepancy is due to the respective foci of each dataset; DCID seeks out cases of cyber incidents and disputes while REI focuses on Russian electoral interference. While a majority of the REI cases include some form of Russian cyber activity, there are a few cases where only material support was provided (eg. Moldova 2014 and Belarus 1994). This discrepancy exemplifies not only the challenges of relying on open source reporting for identifying cyber influence or disruption campaigns, but also differences in defining what counts as an attack. The only country-year that appears in both datasets is Ukraine 2014. We standardized codings across the two datasets using variable definitions from respective codebooks. A severity less than or equal to 2 in DCID’s coding is synonymous in our recoding with REI’s coding for disinformation, a severity between 3 and 7 equals REI’s coding for cyberattack, and no cases in DCID have a severity greater than 7. We adopted Valeriano and Maness (2014)’s approach of sampling on intensity when there are multiple observations in a given time unit. 

## Variable codings
For each incident, we code whether Russia used conventional ground forces, conventional air or sea forces, paramilitary or covert forces, cyber disruption, and information operations. By distinguishing between these five types of aggression, we obtain a clearer picture of the intensity of each case of Russian intervention. The vast majority of cases include at least some type of cyber operations. In a few cases, data limitations preclude coding of non-kinetic activity by Russia or other actors. In Moldova 2005, for example, Russia provided material support for the Communist Party but there is no credible evidence of cyber activities.

The following binary coding criteria were used for each case:

- **resp_infoops** - Did Russia use information operations during this event? That includes propaganda, misinformation campaigns, etc
- **resp_cyberdisrup** - Did Russia use cyber attacks during this operation? That includes hacking, phishing, cyber espionage, DDOS attacks, etc
- **resp_paramil** - Did Russia use paramilitary troops during this event? Special forces, covert troops, speznatz, etc all count
- **resp_convmil_airsea** - Did Russia use conventional naval or air forces during this event?
- **resp_convmil_gro** - Did Russia use conventional ground troops like their army, artillery, tanks, etc during this event?

The complete dataset is provided in the appropriate .csv file. It includes sources used for the codings as well as justifications and explanations where needed.

## Summary statistics
Although data was compiled on Russian intervention against all states from 1994-2018, the statistical analysis is limited to a sample from European states. In alignment with that, we present descriptive statistics of the sample used in the models provided in the main text

```{r}
df_full <- readRDS(paste0(here::here(), '/data/grayzone_model.rds'))

# Limit sample to just European states
df <- df_full %>%
  dplyr::filter(continent == "Europe")

# Subset to variables used in the model
df_vars <- df %>%
  dplyr::select(intensity, NATOmem_MEM, lnmindistkm_rus, gdppc1_2010const, lnpop1, civilwar, demo1, nuclear1, cinc_ratio) %>%
  dplyr::mutate(dplyr::across(where(is.numeric), round, 2)) %>%
  dplyr::mutate_if(is.factor, as.character) %>%
  dplyr::mutate_if(is.character, as.numeric)

# General summary stats
DT::datatable(df_vars)
funModeling::plot_num(df_vars)

gtsummary::tbl_summary(df_vars,
                       missing_text = "(Missing)",
                       label = list(intensity ~ "Intensity", NATOmem_MEM ~ "NATO member", lnmindistkm_rus ~ "Distance from Russia (minimum, log)", lnpop1 ~ "Population (log)", civilwar ~ "Active civil war", demo1 ~ "Democracy", nuclear1 ~ "Nuclear state", cinc_ratio ~ "CINC Ratio")) %>%
  gtsummary::add_n() %>%
  gtsummary::bold_labels()
```

```{r, results = 'asis'}
stargazer::stargazer(df_vars, 
                     title = "Covariate Summary Statistics",
                     covariate.labels = c("Intensity", "NATO member", "Dist. from Russia (minimum, log)", "GDP per capita (2010 const. USD)", "Population (log)", "Active civil war", "Democracy", "Nuclear state", "CINC Ratio"),
                     digits = 1,
                     notes = "Sample includes all European states (1994-2018). Binary variables converted to numeric.",
                     header = FALSE,
                     type = "latex")
```

The distribution of our dependent variable, intensity, is shown below for the full sample (including non-European states)

```{r}
df_full %>%
  dplyr::filter(!intensity == 0) %>%
  dplyr::select(intensity) %>%
  dplyr::group_by(intensity) %>%
  dplyr::summarise(count = dplyr::n()) %>%
  dplyr::mutate(intensity = dplyr::recode_factor(intensity,
                                                 "1" = "1 Info ops",
                                                 "2" = "2 Cyber Disrup.",
                                                 "3" = "3 Paramil.",
                                                 "4" = "4 Mil (Air/sea)",
                                                 "5" = "5 Mil (Gro)")) %>%
  ggplot(aes(x = intensity,
             y = count)
         ) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = count),
            size = 3.5,
            vjust = -0.5) +
  lims(y = c(0, 41)) +
  labs(title = "Intensity of Russia Interventions (1994 - 2018)",
       x = "",
       y = "Number of Country-years"
       ) +
  theme_bw() +
  theme(panel.grid = element_blank(), 
        text = element_text(size = 14)
        )
```

The bivariate correlations between the DV and the two EVs are shown below

```{r}
# DV and EV correlation
df %>%
  dplyr::select(intensity, 
                NATOmem_MEM, lnmindistkm_rus) %>%
  dplyr::mutate(intensity = as.numeric(intensity)) %>%
  GGally::ggpairs()
```

## Case Study: US 2016
A U.S. intelligence assessment released soon after the 2016 election concluded with "high confidence" that "Russian President Vladimir Putin ordered an influence campaign in 2016 aimed at the US presidential election. Russia’s goals were to undermine public faith in the US democratic process, denigrate Secretary Clinton, and harm her electability and potential presidency. We further assess Putin and the Russian Government developed a clear preference for President-elect Trump" [@officeofthedirectorofnationalintelligence_assessingrussianactivities_2017]. Moscow’s influence operations might thus be described as unrestrained, even brazen, and thus motivated entirely by efficiency calculations. Yet the choice to pursue this course of action in the first place was very much constrained by the implicit deterrence posture of the United States. Russia could safely assume that the most powerful military in the world would retaliate for armed attacks against U.S. vital interests. While the United States had not designated its electoral process as "critical infrastructure" to explicitly signal that cyber interference was proscribed, Russia still had to consider the potential for American retaliation. Russia thus sought opportunities to impose costs and seek benefits while minimizing the risk of escalation. It found them through covert manipulation of democratic discourse. Indeed, Russia's electoral interference has gone essentially unpunished by the United States to date, aside from the expulsion of some Russian intelligence officers and the application of some additional sanctions to an already heavy regime put in place after Ukraine. Of course, if Trump’s victory in 2016 or any of his administration's subsequent policies can ever be credited to active measures by the Russian Federation, even in part, it would amount to one of the most consequential intelligence coups in history. It is just as likely, however, that the Russian campaign simply added noise to one of the most chaotic campaigns in U.S. presidential history [@gelman_19thingswe_2017]. Russian information operations appear to be a low-cost gamble to influence an over-determined outcome.

# Alternate model specifications
We run a set of alternate model specifications as robustness checks. Those results are shown below.

## Impute missing control variables
Models 2 and 3 lose some observations due to missing values for control variables; primarily those not available after 2012. Variables with missing data are shown here:

```{r}
naniar::gg_miss_var(df_vars)
ExPanDaR::prepare_missing_values_graph(df, ts_id = "year")
```

We impute values into those control variable columns to avoid losing those observations and display the results below. We do not show results for models 1 and 4 in the original text since those had no missing values and are thus identical.

```{r}
# Prep imputation model
d <- rms::datadist(df)
options(datadist = "d")

# Create new variables to reduce scale problem 
df <- df %>%
  dplyr::mutate(gdppc = gdppc1_2010const/1000) %>%
  dplyr::mutate(milex = milex_sipri/1000)

# Run 10 imputations of the variables with missing data using 0 knots for nonlinear terms
df_imp <- Hmisc::aregImpute(~ cinc1 + 
                              cinc2 +
                              cinc_ratio +
                              milex +
                              milex_sipri +
                              milexpercap_sipri +
                              gdp1_2010const +
                              gdppc1_2010const +
                              gdppc +
                              pop1 +
                              elf +
                              polity1 +
                              NATOmem_MEM +
                              lnmindistkm_rus +
                              cinc_ratio +
                              demo1 +
                              civilwar +
                              nuclear1,
                            nk = 0,
                            tlinear = TRUE, 
                            data = df,
                            n.impute = 10, 
                            pr = FALSE)
```

## Imputed models
This model replicates model 2 in the main text, with control variables imputed:

```{r, results = 'asis', echo = FALSE}
d <- rms::datadist(df)
options(datadist = "d")

# Model
m2_imp <- Hmisc::fit.mult.impute(intensity ~ 
                                   NATOmem_MEM +
                                   lnmindistkm_rus +
                                   demo1 +
                                   nuclear1 +
                                   gdppc +
                                   lnpop1 +
                                   year,
                                 fitter = rms::lrm, 
                                 xtrans = df_imp,
                                 data = df,
                                 x = TRUE,
                                 y = TRUE,
                                 pr = FALSE)

# Country-clustered SE
m2_imp <- rms::robcov(m2_imp, df$cabbrev1)

# Results
m2_imp
plot(anova(m2_imp))

## Bad display/maybe unnecessary
m2_res <- summary(m2_imp, antilog = FALSE)
m2_res <- as.data.frame(m2_res)
m2_res <- m2_res %>%
  dplyr::select("Effect", "S.E.", "Lower 0.95", "Upper 0.95") %>%
  dplyr::slice(1:6) %>%
  tibble::rownames_to_column() %>%
  dplyr::mutate(rowname = dplyr::recode(rowname, 
                'lnmindistkm_rus' = "Russia min. distance", 
                "gdppc" = "GDP per capita",
                'lnpop1' = "Population",
                'NATOmem_MEM - 0:1' = "NATO member", 
                "demo1 - 0:1" = "Democracy",
                "nuclear1 - 1:0" = "Non-nuclear power")) %>%
  dplyr::rename(Variable = rowname)

m2_tab <- xtable::xtable(m2_res,
                         caption = "Model 2, imputed",
                         align = "r|l|l|l|l|l|")
print(m2_tab,
      include.rownames = FALSE,
      comment = FALSE)
```

This model replicates model 3 in the main text. Instead of using population and military expenditure, we replace that with CINC.

```{r, results = 'asis', echo = FALSE}
# Model
m3_imp <- Hmisc::fit.mult.impute(intensity ~ 
                                   NATOmem_MEM +
                                   lnmindistkm_rus +
                                   demo1 +
                                   nuclear1 +
                                   gdppc +
                                   cinc_ratio +
                                   year,
                                 fitter = rms::lrm, 
                                 xtrans = df_imp,
                                 data = df,
                                 x = TRUE,
                                 y = TRUE,
                                 pr = FALSE)

# Country-clustered SE
m3_imp <- rms::robcov(m3_imp, df$cabbrev1)

# Results
m3_imp
plot(anova(m3_imp))

# Ugly table
m3_res <- summary(m3_imp, antilog = FALSE)
m3_res <- as.data.frame(m3_res)
m3_res <- m3_res %>%
  dplyr::select("Effect", "S.E.", "Lower 0.95", "Upper 0.95") %>%
  dplyr::slice(1:5) %>%
  tibble::rownames_to_column() %>%
  dplyr::mutate(rowname = dplyr::recode(rowname, 
                'lnmindistkm_rus' = "Russia min. distance", 
                "gdppc" = "GDP per capita",
                'cinc_ratio' = "CINC ratio",
                'NATOmem_MEM - 0:1' = "NATO member", 
                "demo1 - 0:1" = "Democracy",
                "nuclear1 - 1:0" = "Non-nuclear power")) %>%
  dplyr::rename(Variable = rowname)

m3_tab <- xtable::xtable(m3_res,
                         caption = "Model 3, imputed",
                         align = "r|l|l|l|l|l|")
print(m3_tab,
      include.rownames = FALSE,
      comment = FALSE)
```

We use the subset for models 5 and 6. Imputing for the subsample has to be done separately due to the different n. We remove civilwar because there are less than 5 observations with value 1 which creates unbalanced imputation estimates.

```{r}
# Subset sample
df_conserv <- df %>%
  dplyr::filter(relevant_conserv == 1)

d <- rms::datadist(df_conserv)
options(datadist = "d")

# Impute
df_imp_conserv <- Hmisc::aregImpute(~  cinc1 + 
                                      cinc2 +
                                      cinc_ratio +
                                      milex +
                                      milex_sipri +
                                      milexpercap_sipri +
                                      gdp1_2010const +
                                      gdppc1_2010const +
                                      gdppc +
                                      pop1 +
                                      elf +
                                      polity1 +
                                      NATOmem_MEM +
                                      lnmindistkm_rus +
                                      cinc_ratio +
                                      demo1 +
                                      nuclear1,
                                    nk = 0,
                                    tlinear = TRUE, 
                                    data = df_conserv,
                                    n.impute = 10, 
                                    pr = FALSE)
```

This model replicates model 5 in the main text, with control variables imputed:

```{r, results = 'asis'}
# Model
m5_imp <- Hmisc::fit.mult.impute(intensity ~ 
                                   NATOmem_MEM +
                                   lnmindistkm_rus +
                                   demo1 +
                                   nuclear1 +
                                   gdppc +
                                   lnpop1 +
                                   year,
                                 fitter = rms::lrm, 
                                 xtrans = df_imp_conserv,
                                 data = df_conserv,
                                 x = TRUE,
                                 y = TRUE,
                                 pr = FALSE)

# Country-clusted SE
m5_imp <- rms::robcov(m5_imp, df_conserv$cabbrev1)

# Results
m5_imp
# plot(anova(m5_imp)) # breaks with singular matrix

m5_res <- summary(m5_imp, antilog = FALSE)
m5_res <- as.data.frame(m5_res)
m5_res <- m5_res %>%
  dplyr::select("Effect", "S.E.", "Lower 0.95", "Upper 0.95") %>%
  dplyr::slice(1:6) %>%
  tibble::rownames_to_column() %>%
  dplyr::mutate(rowname = dplyr::recode(rowname, 
                'lnmindistkm_rus' = "Russia min. distance", 
                "gdppc" = "GDP per capita",
                'lnpop1' = "Population",
                'NATOmem_MEM - 0:1' = "NATO member", 
                "demo1 - 0:1" = "Democracy",
                "nuclear1 - 1:0" = "Non-nuclear power")) %>%
  dplyr::rename(Variable = rowname)

m5_tab <- xtable::xtable(m5_res,
                         caption = "Model 5, imputed",
                         align = "r|l|l|l|l|l|")
print(m5_tab,
      include.rownames = FALSE,
      comment = FALSE)
```

This model replicates model 6 in the main text, with control variables imputed. We remove civil war from here:

```{r, results = 'asis'}
# Model
m6_imp <- Hmisc::fit.mult.impute(intensity ~ 
                                   NATOmem_MEM +
                                   lnmindistkm_rus +
                                   demo1 +
                                   nuclear1 +
                                   gdppc +
                                   cinc_ratio +
                                   year,
                                 fitter = rms::lrm, 
                                 xtrans = df_imp_conserv,
                                 data = df_conserv,
                                 x = TRUE,
                                 y = TRUE,
                                 pr = FALSE)

# Country-clustered SE
m6_imp <- rms::robcov(m6_imp, df_conserv$cabbrev1)

# Results
m6_imp
# plot(anova(m6_imp)) # beraks with singular matrix

m6_res <- summary(m6_imp, antilog = FALSE)
m6_res <- as.data.frame(m6_res)
m6_res <- m6_res %>%
  dplyr::select("Effect", "S.E.", "Lower 0.95", "Upper 0.95") %>%
  dplyr::slice(1:5) %>%
  tibble::rownames_to_column() %>%
  dplyr::mutate(rowname = dplyr::recode(rowname, 
                'lnmindistkm_rus' = "Russia min. distance", 
                'gdppc' = "GDP per capita",
                'cinc_ratio' = "CINC ratio",
                'NATOmem_MEM - 0:1' = "NATO member", 
                "demo1 - 0:1" = "Democracy",
                "nuclear1 - 1:0" = "Non-nuclear power")) %>%
  dplyr::rename(Variable = rowname)

m6_tab <- xtable::xtable(m6_res,
                         caption = "Model 6, imputed",
                         align = "r|l|l|l|l|l|")
print(m6_tab,
      include.rownames = FALSE,
      comment = FALSE)
```

## Zero inflated ordered probit
Test alternate model of zero-inflated ordered probit, since 95% of Europe country-years from 1994-2018 experienced no Russian attack.

```{r, eval = FALSE}
#This program estimates the ZIOP loglikelihood function

ZIOP <- function(est,Y,X,Z,data) {					      
	n=nrow(data)							      					  
	llik <- matrix(0, nrow=n, ncol = 1)
	y.cat<-nlevels(as.factor(Y))
	y0<-sort(unique(Y))
	V<-matrix(NA,nrow(data),y.cat)
	for(k in 1:y.cat){
		V[,k]<-Y==y0[k]
		}
	tau<-rep(1,max(Y))
	for (i in 1:max(Y)){
		tau[i]<-ifelse(i==1,est[i],tau[i-1]+exp(est[i]))
		}
	gamma<-est[(y.cat):(y.cat+ncol(Z)-1)]
	beta<-est[(y.cat+ncol(Z)):length(est)]
	ZG<-Z%*%gamma
	XB<-X%*%beta
	
	cprobs<-matrix(nrow=length(XB),ncol=y.cat)
	probs<-matrix(nrow=n,ncol=y.cat)
	     
	for(j in 1:(y.cat-1)){
		
		cprobs[,j]<-pnorm(tau[j]-XB)
		
		}
	
	probs[,y.cat]<-(1-cprobs[,(y.cat-1)])*pnorm(ZG) 
	probs[,1]<-(cprobs[,1])*pnorm(ZG)+(1-pnorm(ZG))	
	
	for(j in 2:(y.cat-1)){			
		
		probs[,j]<-(cprobs[,j]-cprobs[,(j-1)])*(pnorm(ZG))
		
		}
	
	llik<--1*sum( log(probs[V]) )
	
	return(llik)
	
	}



#set starting parameters
est <- rbind(.1,.1,.1,.1,.1,.1,.1,.1)

#set data, Y, X, and Z
data <- df
Y <- data$intensity
X <- cbind(data$NATOmem_MEM, 
           data$lnmindistkm_rus)
Z <- cbind(1, 
           data$NATOmem_MEM, 
           data$lnmindistkm_rus)

#optimize
output.ZIOP <- nlm(f = ZIOP,p=est, Y = Y, X = X, Z = Z , iterlim = 500, data = data, hessian=TRUE)
print(output.ZIOP)
vcv<-solve(output.ZIOP$hessian)
vcv 

```

## Alternate samples
### Fix functions
We include the same code used to fix package functions used in the original model to ensure replicability and comparability

#### polr function
We use the polr function from the MASS package to compute an ordered probit. The base version of the function in the R package contains an error that does not take the log of differences in the reposed zetas which results in an optimization error where vmmin is infinite. A fixed version of the function was created and is loaded below. For this reason, the polr function is not loaded from the MASS package, but instead from the function below. All secondary functions from the MASS package do work

```{r}
# file MASS/R/polr.R
# copyright (C) 1994-2008 W. N. Venables and B. D. Ripley
# Use of transformed intercepts contributed by David Firth
#
#  This program is free software; you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation; either version 2 or 3 of the License
#  (at your option).
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  A copy of the GNU General Public License is available at
#  http://www.r-project.org/Licenses/
#
polr <- function(formula, data, weights, start, ..., subset,
                 na.action, contrasts = NULL, Hess = FALSE,
                 model = TRUE,
                 method = c("logistic", "probit", "cloglog", "cauchit"))
{
    logit <- function(p) log(p/(1 - p))

    fmin <- function(beta) {
        theta <- beta[pc + 1L:q]
        gamm <- c(-Inf, cumsum(c(theta[1L], exp(theta[-1L]))), Inf)
        eta <- offset
        if (pc > 0)
            eta <- eta + drop(x %*% beta[1L:pc])
        pr <- pfun(gamm[y + 1] - eta) - pfun(gamm[y] - eta)
        if (all(pr > 0))
            -sum(wt * log(pr))
        else Inf
    }

    gmin <- function(beta)
    {
        jacobian <- function(theta) { ## dgamma by dtheta matrix
            k <- length(theta)
            etheta <- exp(theta)
            mat <- matrix(0 , k, k)
            mat[, 1] <- rep(1, k)
            for (i in 2:k) mat[i:k, i] <- etheta[i]
            mat
        }
        theta <- beta[pc + 1L:q]
        gamm <- c(-Inf, cumsum(c(theta[1L], exp(theta[-1L]))), Inf)
        eta <- offset
        if(pc > 0) eta <- eta + drop(x %*% beta[1L:pc])
        pr <- pfun(gamm[y+1] - eta) - pfun(gamm[y] - eta)
        p1 <- dfun(gamm[y+1] - eta)
        p2 <- dfun(gamm[y] - eta)
        g1 <- if(pc > 0) t(x) %*% (wt*(p1 - p2)/pr) else numeric(0)
        xx <- .polrY1*p1 - .polrY2*p2
        g2 <- - t(xx) %*% (wt/pr)
        g2 <- t(g2) %*% jacobian(theta)
        if(all(pr > 0)) c(g1, g2) else rep(NA, pc+q)
    }

    m <- match.call(expand.dots = FALSE)
    method <- match.arg(method)
    pfun <- switch(method, logistic = plogis, probit = pnorm,
                   cloglog = pgumbel, cauchit = pcauchy)
    dfun <- switch(method, logistic = dlogis, probit = dnorm,
                   cloglog = dgumbel, cauchit = dcauchy)
    if(is.matrix(eval.parent(m$data)))
        m$data <- as.data.frame(data)
    m$start <- m$Hess <- m$method <- m$model <- m$... <- NULL
    m[[1L]] <- as.name("model.frame")
    m <- eval.parent(m)
    Terms <- attr(m, "terms")
    x <- model.matrix(Terms, m, contrasts)
    xint <- match("(Intercept)", colnames(x), nomatch=0L)
    n <- nrow(x)
    pc <- ncol(x)
    cons <- attr(x, "contrasts") # will get dropped by subsetting
    if(xint > 0) {
        x <- x[, -xint, drop=FALSE]
        pc <- pc - 1
    } else warning("an intercept is needed and assumed")
    wt <- model.weights(m)
    if(!length(wt)) wt <- rep(1, n)
    offset <- model.offset(m)
    if(length(offset) <= 1) offset <- rep(0, n)
    y <- model.response(m)
    if(!is.factor(y)) stop("response must be a factor")
    lev <- levels(y)
    if(length(lev) <= 2) stop("response must have 3 or more levels")
    y <- unclass(y)
    q <- length(lev) - 1
    Y <- matrix(0, n, q)
    .polrY1 <- col(Y) == y
    .polrY2 <- col(Y) == y - 1
    if(missing(start)) {
      # try something that should always work -tjb
      u <- as.integer(table(y))
      u <- (cumsum(u)/sum(u))[1:q]
      zetas <-
         switch(method,
                "logistic"= qlogis(u),
                "probit"=   qnorm(u),
                "cauchit"=  qcauchy(u),
                "cloglog"=  -log(-log(u)) )
      s0 <- c(rep(0,pc),zetas[1],log(diff(zetas)))

##         # try logistic/probit regression on 'middle' cut
##         q1 <- length(lev) %/% 2
##         y1 <- (y > q1)
##         X <- cbind(Intercept = rep(1, n), x)
##         fit <-
##             switch(method,
##                    "logistic"= glm.fit(X, y1, wt, family = binomial(), offset = offset),
##                    "probit" = glm.fit(X, y1, wt, family = binomial("probit"), offset = offset),
##                    ## this is deliberate, a better starting point
##                    "cloglog" = glm.fit(X, y1, wt, family = binomial("probit"), offset = offset),
##                    "cauchit" = glm.fit(X, y1, wt, family = binomial("cauchit"), offset = offset))
##         if(!fit$converged)
##             stop("attempt to find suitable starting values failed")
##         coefs <- fit$coefficients
##         if(any(is.na(coefs))) {
##             warning("design appears to be rank-deficient, so dropping some coefs")
##             keep <- names(coefs)[!is.na(coefs)]
##             coefs <- coefs[keep]
##             x <- x[, keep[-1L], drop = FALSE]
##             pc <- ncol(x)
##           }
##         spacing <- logit((1L:q)/(q+1)) # just a guess
##         if(method != "logistic") spacing <- spacing/1.7
##         gammas <- -coefs[1L] + spacing - spacing[q1]
##         thetas <- c(gammas[1L], log(diff(gammas)))
##         s0 <- c(coefs[-1L], thetas)
    } else if(length(start) != pc + q)
	stop("'start' is not of the correct length")
    else {
        s0 <- if(pc > 0) c(start[seq_len(pc+1)], log(diff(start[-seq_len(pc)])))
        else c(start[1L], log(diff(start)))
      }
    res <- optim(s0, fmin, gmin, method="BFGS", hessian = Hess, ...)
    beta <- res$par[seq_len(pc)]
    theta <- res$par[pc + 1L:q]
    zeta <- cumsum(c(theta[1L],exp(theta[-1L])))
    deviance <- 2 * res$value
    niter <- c(f.evals=res$counts[1L], g.evals=res$counts[2L])
    names(zeta) <- paste(lev[-length(lev)], lev[-1L], sep="|")
    if(pc > 0) {
        names(beta) <- colnames(x)
        eta <- offset + drop(x %*% beta)
    } else eta <- offset + rep(0, n)

    cumpr <- matrix(pfun(matrix(zeta, n, q, byrow=TRUE) - eta), , q)
    fitted <- t(apply(cumpr, 1L, function(x) diff(c(0, x, 1))))
    dimnames(fitted) <- list(row.names(m), lev)
    fit <- list(coefficients = beta, zeta = zeta, deviance = deviance,
                fitted.values = fitted, lev = lev, terms = Terms,
                df.residual = sum(wt) - pc - q, edf = pc + q, n = sum(wt),
                nobs = sum(wt),
                call = match.call(), method = method,
		convergence = res$convergence, niter = niter, lp = eta)
    if(Hess) {
        dn <- c(names(beta), names(zeta))
        H <- res$hessian
        dimnames(H) <- list(dn, dn)
        fit$Hessian <- H
    }
    if(model) fit$model <- m
    fit$na.action <- attr(m, "na.action")
    fit$contrasts <- cons
    fit$xlevels <- .getXlevels(Terms, m)
    class(fit) <- "polr"
    fit
}

print.polr <- function(x, ...)
{
    if(!is.null(cl <- x$call)) {
        cat("Call:\n")
        dput(cl, control=NULL)
    }
    if(length(coef(x))) {
        cat("\nCoefficients:\n")
        print(coef(x), ...)
    } else {
        cat("\nNo coefficients\n")
    }
    cat("\nIntercepts:\n")
    print(x$zeta, ...)
    cat("\nResidual Deviance:", format(x$deviance, nsmall=2), "\n")
    cat("AIC:", format(x$deviance + 2*x$edf, nsmall=2), "\n")
    if(nzchar(mess <- naprint(x$na.action))) cat("(", mess, ")\n", sep="")
    if(x$convergence > 0)
        cat("Warning: did not converge as iteration limit reached\n")
    invisible(x)
}

vcov.polr <- function(object, ...)
{
    jacobian <- function(theta) { ## dgamma by dtheta matrix
        k <- length(theta)
        etheta <- exp(theta)
        mat <- matrix(0 , k, k)
        mat[, 1] <- rep(1, k)
        for (i in 2:k) mat[i:k, i] <- etheta[i]
        mat
    }

    if(is.null(object$Hessian)) {
        message("\nRe-fitting to get Hessian\n")
	utils::flush.console()
        object <- update(object, Hess=TRUE,
                         start=c(object$coefficients, object$zeta))
    }
    vc <- MASS::ginv(object$Hessian)
    pc <- length(coef(object))
    gamma <- object$zeta
    z.ind <- pc + seq_along(gamma)
    theta <- c(gamma[1L], log(diff(gamma)))
    J <- jacobian(theta)
    A <- diag(pc + length(gamma))
    A[z.ind, z.ind] <- J
    V <- A %*% vc %*% t(A)
    structure(V,  dimnames = dimnames(object$Hessian))
}

summary.polr <- function(object, digits = max(3, .Options$digits - 3),
                         correlation = FALSE, ...)
{
    cc <- c(coef(object), object$zeta)
    pc <- length(coef(object))
    q <- length(object$zeta)
    coef <- matrix(0, pc+q, 3, dimnames=list(names(cc),
                               c("Value", "Std. Error", "t value")))
    coef[, 1] <- cc
    vc <- vcov(object)
    coef[, 2] <- sd <- sqrt(diag(vc))
    coef[, 3] <- coef[, 1]/coef[, 2]
    object$coefficients <- coef
    object$pc <- pc
    object$digits <- digits
    if(correlation)
        object$correlation <- (vc/sd)/rep(sd, rep(pc+q, pc+q))
    class(object) <- "summary.polr"
    object
}

print.summary.polr <- function(x, digits = x$digits, ...)
{
    if(!is.null(cl <- x$call)) {
        cat("Call:\n")
        dput(cl, control=NULL)
    }
    coef <- format(round(x$coefficients, digits=digits))
    pc <- x$pc
    if(pc > 0) {
        cat("\nCoefficients:\n")
        print(x$coefficients[seq_len(pc), , drop=FALSE], quote = FALSE,
              digits = digits, ...)
    } else {
        cat("\nNo coefficients\n")
    }
    cat("\nIntercepts:\n")
    print(coef[(pc+1):nrow(coef), , drop=FALSE], quote = FALSE,
          digits = digits, ...)
    cat("\nResidual Deviance:", format(x$deviance, nsmall=2), "\n")
    cat("AIC:", format(x$deviance + 2*x$edf, nsmall=2), "\n")
    if(nzchar(mess <- naprint(x$na.action))) cat("(", mess, ")\n", sep="")
    if(!is.null(correl <- x$correlation)) {
        cat("\nCorrelation of Coefficients:\n")
        ll <- lower.tri(correl)
        correl[ll] <- format(round(correl[ll], digits))
        correl[!ll] <- ""
        print(correl[-1, -ncol(correl)], quote = FALSE, ...)
    }
    invisible(x)
}

predict.polr <- function(object, newdata, type=c("class","probs"), ...)
{
    if(!inherits(object, "polr")) stop("not a \"polr\" object")
    type <- match.arg(type)
    if(missing(newdata)) Y <- object$fitted
    else {
        newdata <- as.data.frame(newdata)
        Terms <- delete.response(object$terms)
        m <- model.frame(Terms, newdata, na.action = function(x) x,
                         xlev = object$xlevels)
        if (!is.null(cl <- attr(Terms, "dataClasses")))
            .checkMFClasses(cl, m)
        X <- model.matrix(Terms, m, contrasts = object$contrasts)
        xint <- match("(Intercept)", colnames(X), nomatch=0L)
        if(xint > 0) X <- X[, -xint, drop=FALSE]
        n <- nrow(X)
        q <- length(object$zeta)
        eta <- drop(X %*% object$coefficients)
        pfun <- switch(object$method, logistic = plogis, probit = pnorm,
                       cloglog = pgumbel, cauchit = pcauchy)
        cumpr <- matrix(pfun(matrix(object$zeta, n, q, byrow=TRUE) - eta), , q)
        Y <- t(apply(cumpr, 1L, function(x) diff(c(0, x, 1))))
        dimnames(Y) <- list(rownames(X), object$lev)
    }
    if(missing(newdata) && !is.null(object$na.action))
        Y <- napredict(object$na.action, Y)
    switch(type, class = {
        Y <- factor(max.col(Y), levels=seq_along(object$lev),
                    labels=object$lev)
    }, probs = {})
    drop(Y)
}

extractAIC.polr <- function(fit, scale = 0, k = 2, ...)
{
    edf <- fit$edf
    c(edf, deviance(fit) + k * edf)
}

model.frame.polr <- function(formula, ...)
{
    dots <- list(...)
    nargs <- dots[match(c("data", "na.action", "subset"), names(dots), 0)]
    if(length(nargs) || is.null(formula$model)) {
        m <- formula$call
        m$start <- m$Hess <- m$... <- NULL
        m[[1L]] <- as.name("model.frame")
        m[names(nargs)] <- nargs
        if (is.null(env <- environment(formula$terms))) env <- parent.frame()
        data <- eval(m, env)
        if(!is.null(mw <- m$weights)) {
            nm <- names(data)
            nm[match("(weights)", nm)] <- as.character(mw)
            names(data) <- nm
        }
        data
    } else formula$model
}

pgumbel <- function(q, loc = 0, scale = 1, lower.tail = TRUE)
{
    q <- (q - loc)/scale
    p <- exp(-exp(-q))
    if (!lower.tail) 1 - p else p
}

dgumbel <- function (x, loc = 0, scale = 1, log = FALSE)
{
    x <- (x - loc)/scale
    d <- log(1/scale) - x - exp(-x)
    d[is.nan(d)] <- -Inf                # -tjb
    if (!log) exp(d) else d
}

anova.polr <- function (object, ..., test = c("Chisq", "none"))
{
    test <- match.arg(test)
    dots <- list(...)
    if (length(dots) == 0L)
        stop('anova is not implemented for a single "polr" object')
    mlist <- list(object, ...)
    nt <- length(mlist)
    dflis <- sapply(mlist, function(x) x$df.residual)
    s <- order(dflis, decreasing = TRUE)
    mlist <- mlist[s]
    if (any(!sapply(mlist, inherits, "polr")))
        stop('not all objects are of class "polr"')
    ns <- sapply(mlist, function(x) length(x$fitted.values))
    if(any(ns != ns[1L]))
        stop("models were not all fitted to the same size of dataset")
    rsp <- unique(sapply(mlist, function(x) paste(formula(x)[2L])))
    mds <- sapply(mlist, function(x) paste(formula(x)[3L]))
    dfs <- dflis[s]
    lls <- sapply(mlist, function(x) deviance(x))
    tss <- c("", paste(1L:(nt - 1), 2:nt, sep = " vs "))
    df <- c(NA, -diff(dfs))
    x2 <- c(NA, -diff(lls))
    pr <- c(NA, 1 - pchisq(x2[-1L], df[-1L]))
    out <- data.frame(Model = mds, Resid.df = dfs, Deviance = lls,
                      Test = tss, Df = df, LRtest = x2, Prob = pr)
    names(out) <- c("Model", "Resid. df", "Resid. Dev", "Test",
                    "   Df", "LR stat.", "Pr(Chi)")
    if (test == "none") out <- out[, 1L:6]
    class(out) <- c("Anova", "data.frame")
    attr(out, "heading") <-
        c("Likelihood ratio tests of ordinal regression models\n",
          paste("Response:", rsp))
    out
}

polr.fit <- function(x, y, wt, start, offset, method)
{
    logit <- function(p) log(p/(1 - p))

    fmin <- function(beta) {
        theta <- beta[pc + 1L:q]
        gamm <- c(-Inf, cumsum(c(theta[1L], exp(theta[-1L]))), Inf)
        eta <- offset
        if (pc > 0)
            eta <- eta + drop(x %*% beta[1L:pc])
        pr <- pfun(gamm[y + 1] - eta) - pfun(gamm[y] - eta)
        if (all(pr > 0))
            -sum(wt * log(pr))
        else Inf
    }

    gmin <- function(beta)
    {
        jacobian <- function(theta) { ## dgamma by dtheta matrix
            k <- length(theta)
            etheta <- exp(theta)
            mat <- matrix(0 , k, k)
            mat[, 1] <- rep(1, k)
            for (i in 2:k) mat[i:k, i] <- etheta[i]
            mat
        }
        theta <- beta[pc + 1L:q]
        gamm <- c(-Inf, cumsum(c(theta[1L], exp(theta[-1L]))), Inf)
        eta <- offset
        if(pc > 0) eta <- eta + drop(x %*% beta[1L:pc])
        pr <- pfun(gamm[y+1] - eta) - pfun(gamm[y] - eta)
        p1 <- dfun(gamm[y+1] - eta)
        p2 <- dfun(gamm[y] - eta)
        g1 <- if(pc > 0) t(x) %*% (wt*(p1 - p2)/pr) else numeric(0)
        xx <- .polrY1*p1 - .polrY2*p2
        g2 <- - t(xx) %*% (wt/pr)
        g2 <- t(g2) %*% jacobian(theta)
        if(all(pr > 0)) c(g1, g2) else rep(NA, pc+q)
    }

    pfun <- switch(method, logistic = plogis, probit = pnorm,
                   cloglog = pgumbel, cauchit = pcauchy)
    dfun <- switch(method, logistic = dlogis, probit = dnorm,
                   cloglog = dgumbel, cauchit = dcauchy)
    n <- nrow(x)
    pc <- ncol(x)
    lev <- levels(y)
    if(length(lev) <= 2L) stop("response must have 3 or more levels")
    y <- unclass(y)
    q <- length(lev) - 1L
    Y <- matrix(0, n, q)
    .polrY1 <- col(Y) == y
    .polrY2 <- col(Y) == y - 1L
    # pc could be 0.
    s0 <- if(pc > 0) c(start[seq_len(pc+1)], diff(start[-seq_len(pc)]))
    else c(start[1L], diff(start))
    res <- optim(s0, fmin, gmin, method="BFGS")
    beta <- res$par[seq_len(pc)]
    theta <- res$par[pc + 1L:q]
    zeta <- cumsum(c(theta[1L],exp(theta[-1L])))
    deviance <- 2 * res$value
    names(zeta) <- paste(lev[-length(lev)], lev[-1L], sep="|")
    if(pc > 0) {
        names(beta) <- colnames(x)
        eta <- drop(x %*% beta)
    } else {
        eta <- rep(0, n)
    }
    list(coefficients = beta, zeta = zeta, deviance = deviance)
}

profile.polr <- function(fitted, which = 1L:p, alpha = 0.01,
                         maxsteps = 10, del = zmax/5, trace = FALSE, ...)
{
    Pnames <- names(B0 <- coefficients(fitted))
    pv0 <- t(as.matrix(B0))
    p <- length(Pnames)
    if(is.character(which)) which <- match(which, Pnames)
    summ <- summary(fitted)
    std.err <- summ$coefficients[, "Std. Error"]
    mf <- model.frame(fitted)
    n <- length(Y <- model.response(mf))
    O <- model.offset(mf)
    if(!length(O)) O <- rep(0, n)
    W <- model.weights(mf)
    if(length(W) == 0L) W <- rep(1, n)
    OriginalDeviance <- deviance(fitted)
    X <- model.matrix(fitted)[, -1L, drop=FALSE] # drop intercept
    zmax <- sqrt(qchisq(1 - alpha, 1))
    profName <- "z"
    prof <- vector("list", length=length(which))
    names(prof) <- Pnames[which]
    start <- c(fitted$coefficients, fitted$zeta)
    for(i in which) {
        zi <- 0
        pvi <- pv0
        Xi <- X[,  - i, drop = FALSE]
        pi <- Pnames[i]
        for(sgn in c(-1, 1)) {
            if(trace) {
                message("\nParameter:", pi, c("down", "up")[(sgn + 1)/2 + 1])
                utils::flush.console()
            }
            step <- 0
            z <- 0
            ## LP is the linear predictor including offset.
            ## LP <- X %*% fitted$coef + O
            while((step <- step + 1) < maxsteps && abs(z) < zmax) {
                bi <- B0[i] + sgn * step * del * std.err[i]
                o <- O + X[, i] * bi
                fm <- polr.fit(x = Xi, y = Y, wt = W, start = start[-i],
                               offset = o, method = fitted$method)
                ri <- pv0
                ri[, names(coef(fm))] <- coef(fm)
                ri[, pi] <- bi
                pvi <- rbind(pvi, ri)
                zz <- fm$deviance - OriginalDeviance
                if(zz > - 1e-3) zz <- max(zz, 0)
                else stop("profiling has found a better solution, so original fit had not converged")
                z <- sgn * sqrt(zz)
                zi <- c(zi, z)
            }
        }
        si <- order(zi)
        prof[[pi]] <- structure(data.frame(zi[si]), names = profName)
        prof[[pi]]$par.vals <- pvi[si, ]
    }
    val <- structure(prof, original.fit = fitted, summary = summ)
    class(val) <- c("profile.polr", "profile")
    val
}

confint.polr <- function(object, parm, level = 0.95, trace = FALSE, ...)
{
    pnames <- names(coef(object))
    if(missing(parm)) parm <- seq_along(pnames)
    else if(is.character(parm))  parm <- match(parm, pnames, nomatch = 0L)
    message("Waiting for profiling to be done...")
    utils::flush.console()
    object <- profile(object, which = parm, alpha = (1. - level)/4.,
                      trace = trace)
    confint(object, parm=parm, level=level, trace=trace, ...)
}

confint.profile.polr <-
  function(object, parm = seq_along(pnames), level = 0.95, ...)
{
    of <- attr(object, "original.fit")
    pnames <- names(coef(of))
    if(is.character(parm))  parm <- match(parm, pnames, nomatch = 0L)
    a <- (1-level)/2
    a <- c(a, 1-a)
    pct <- paste(round(100*a, 1), "%")
    ci <- array(NA, dim = c(length(parm), 2L),
                dimnames = list(pnames[parm], pct))
    cutoff <- qnorm(a)
    for(pm in parm) {
        pro <- object[[ pnames[pm] ]]
        if(length(pnames) > 1L)
            sp <- spline(x = pro[, "par.vals"][, pm], y = pro[, 1])
        else sp <- spline(x = pro[, "par.vals"], y = pro[, 1])
        ci[pnames[pm], ] <- approx(sp$y, sp$x, xout = cutoff)$y
    }
    drop(ci)
}

logLik.polr <- function(object, ...)
    structure(-0.5 * object$deviance, df = object$edf, class = "logLik")

simulate.polr <- function(object, nsim = 1, seed = NULL, ...)
{
    if(!is.null(object$model) && any(model.weights(object$model) != 1))
        stop("weighted fits are not supported")

    rgumbel <- function(n, loc = 0, scale = 1) loc - scale*log(rexp(n))

    ## start the same way as simulate.lm
    if(!exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE))
        runif(1)                     # initialize the RNG if necessary
    if(is.null(seed))
        RNGstate <- get(".Random.seed", envir = .GlobalEnv)
    else {
        R.seed <- get(".Random.seed", envir = .GlobalEnv)
	set.seed(seed)
        RNGstate <- structure(seed, kind = as.list(RNGkind()))
        on.exit(assign(".Random.seed", R.seed, envir = .GlobalEnv))
    }
    rfun <- switch(object$method, logistic = rlogis, probit = rnorm,
                   cloglog = rgumbel, cauchit = rcauchy)
    eta <- object$lp
    n <- length(eta)
    res <- cut(rfun(n*nsim, eta),
               c(-Inf, object$zeta, Inf),
               labels = colnames(fitted(object)),
               ordered_result = TRUE)
    val <- split(res, rep(seq_len(nsim), each=n))
    names(val) <- paste("sim", seq_len(nsim), sep="_")
    val <- as.data.frame(val)
    if (!is.null(nm <- rownames(fitted(object)))) row.names(val) <- nm
    attr(val, "seed") <- RNGstate
    val
}
```

#### stargazer function
For odds ratios, stargazer recauclates the significance levels based on the new coefficients which it shouldn't. This is correct with a function here created by [cimentadaj](https://cimentadaj.github.io/blog/2016-08-22-producing-stargazer-tables-with-odds-ratios-and-standard-errors-in-r/producing-stargazer-tables-with-odds-ratios-and-standard-errors-in-r/)

```{r}
stargazer2 <- function(model, odd.ratio = F, ...) {
  if(!("list" %in% class(model))) model <- list(model)
    
  if (odd.ratio) {
    coefOR2 <- lapply(model, function(x) exp(coef(x)))
    seOR2 <- lapply(model, function(x) exp(coef(x)) * summary(x)$coef[, 2])
    p2 <- lapply(model, function(x) summary(x)$coefficients[, 4])
    stargazer::stargazer(model, coef = coefOR2, se = seOR2, p = p2, ...)
    
  } else {
    stargazer::stargazer(model, ...)
  }
}
```

### Expansive sample
Expansive subset includes all European states that meet the 3-prong criteria for potential target or are in the data as targets of an attack post-1994.

```{r}
df_m1 <- df %>%
  dplyr::filter(relevant_expansive == 1)
```

Replicate model 1:

```{r}
df_m1vars <- df_m1 %>%
  dplyr::select(intensity, NATOmem_MEM, lnmindistkm_rus, dplyr::starts_with("year_"))

# Model
m1 <- polr(intensity ~ .,
           data = df_m1vars,
           method = "probit",
           Hess = TRUE)

# Country-clustered SE
m1 <- lmtest::coeftest(m1, vcov = sandwich::vcovCL(m1, factor(df_m1$cname1)))

# Odds ratio
m1_or <- stargazer2(m1, 
           apply.coef = exp,
           omit = "year",
           title = "Model 1 Odds Ratios",
           p.auto = FALSE,
           t.auto = FALSE,
           type = "text")
```

Replicate model 2:

```{r}
df_m2vars <- df_m1 %>%
  dplyr::select(intensity, NATOmem_MEM, lnmindistkm_rus, demo1, nuclear1, gdppc1_2010const, lnpop1, dplyr::starts_with("year_")) %>%
  dplyr::mutate(gdppc = gdppc1_2010const/1000) %>%
  dplyr::select(-gdppc1_2010const)

# Model
m2 <- polr(intensity ~ .,
                 data = df_m2vars,
                 method = "probit",
                 Hess = TRUE)

# Country-clustered SE
m2 <- lmtest::coeftest(m2, vcov = sandwich::vcovCL(m2, factor(df_m1$cname1)))

# Odds ratio
m2_or <- stargazer2(m2, 
           apply.coef = exp,
           omit = "year",
           title = "Model 2 Odds Ratios",
           p.auto = FALSE,
           t.auto = FALSE,
           type = "text")
```

Replicate model 3:

```{r}
df_m3vars <- df_m1 %>%
  dplyr::select(intensity, NATOmem_MEM, lnmindistkm_rus, demo1, nuclear1, gdppc1_2010const, lnpop1, milex_sipri, dplyr::starts_with("year_")) %>%
  dplyr::mutate(gdppc = gdppc1_2010const/1000) %>%
  dplyr::mutate(milex = milex_sipri/1000) %>%
  dplyr::select(-gdppc1_2010const, -milex_sipri)

# Model
m3 <- polr(intensity ~ .,
           data = df_m3vars,
           method = "probit",
           Hess = TRUE)

# Country-clustered SE
m3 <- lmtest::coeftest(m3, vcov = sandwich::vcovCL(m3, factor(df_m1$cname1)))

# Odds ratio
m3_or <- stargazer2(m3, 
           apply.coef = exp,
           omit = "year",
           title = "Model 3 Odds Ratios",
           p.auto = FALSE,
           t.auto = FALSE,
           type = "text")
```

### Known targets
Known attack includes only country-years that were targets of a Russian intervention after 1994

```{r}
df_m4 <- df %>%
  dplyr::mutate(intensity = as.integer(intensity)) %>%
  dplyr::filter(intensity > 1) %>% # Values of 0 for intensity are internally coded as the first factor value. This filters to only include factor values 2 or greater, which corresponds to numeric intensity values 1 or greater
  dplyr::mutate(intensity = as.factor(intensity))
```

Replicate model 1:

```{r}
df_m4vars <- df_m4 %>%
  dplyr::select(intensity, NATOmem_MEM, lnmindistkm_rus, dplyr::starts_with("year_"))

# Model
m4 <- polr(intensity ~ .,
           data = df_m4vars,
           method = "probit",
           Hess = TRUE)

# Country-clustered SE
m4 <- lmtest::coeftest(m4, vcov = sandwich::vcovCL(m4, factor(df_m4$cname1)))

# Odds ratio
m4_or <- stargazer2(m4, 
           apply.coef = exp,
           omit = "year",
           title = "Model 4 Odds Ratios",
           p.auto = FALSE,
           t.auto = FALSE,
           type = "text")
```

Replicate model 2:

```{r}
df_m5vars <- df_m1 %>%
  dplyr::select(intensity, NATOmem_MEM, lnmindistkm_rus, demo1, nuclear1, gdppc1_2010const, lnpop1, dplyr::starts_with("year_")) %>%
  dplyr::mutate(gdppc = gdppc1_2010const/1000) %>%
  dplyr::select(-gdppc1_2010const)

# Model
m5 <- polr(intensity ~ .,
                 data = df_m5vars,
                 method = "probit",
                 Hess = TRUE)

# Country-clustered SE
m5 <- lmtest::coeftest(m5, vcov = sandwich::vcovCL(m5, factor(df_m1$cname1)))

# Odds ratio
m5_or <- stargazer2(m5, 
           apply.coef = exp,
           omit = "year",
           title = "Model 5 Odds Ratios",
           p.auto = FALSE,
           t.auto = FALSE,
           type = "text")
```

Replicate model 3:

```{r}
df_m6vars <- df_m1 %>%
  dplyr::select(intensity, NATOmem_MEM, lnmindistkm_rus, demo1, nuclear1, gdppc1_2010const, lnpop1, milex_sipri, dplyr::starts_with("year_")) %>%
  dplyr::mutate(gdppc = gdppc1_2010const/1000) %>%
  dplyr::mutate(milex = milex_sipri/1000) %>%
  dplyr::select(-gdppc1_2010const, -milex_sipri)

# Model
m6 <- polr(intensity ~ .,
           data = df_m6vars,
           method = "probit",
           Hess = TRUE)

# Country-clustered SE
m6 <- lmtest::coeftest(m6, vcov = sandwich::vcovCL(m6, factor(df_m1$cname1)))

# Odds ratio
m6_or <- stargazer2(m6, 
           apply.coef = exp,
           omit = "year",
           title = "Model 6 Odds Ratios",
           p.auto = FALSE,
           t.auto = FALSE,
           type = "text")
```

### Compiled results
```{r}
# Make list of models
models <- list(m1, m2, m3, m4, m5, m6)

# Main coefficients
texreg::screenreg(models,
                  stars = c(0.01, 0.05, 0.1),
                  omit.coef = "(y)",
                  custom.coef.names = c("NATO member",
                                     "Russia min. distance",
                                     "Democracy",
                                     "Nuclear power",
                                     "Population",
                                     "GDP per capita",
                                     "Mil. expenditure"),
                  custom.gof.rows = list("Fixed effects" = c("Yes", "Yes", "Yes", "Yes", "Yes", "Yes")), 
                  custom.header = list("Expanded Euro sample" = 1:3, "Known targets sample" = 4:6))

# Odds ratio
stargazer2(models, 
           apply.coef = exp,
           omit = "year",
           title = "Odds Ratios",
           column.labels   = c("Expanded Euro sample", "Known targets sample"),
           column.separate = c(3, 3),
           custom.coef.names = c("NATO member",
                                 "Russia min. distance",
                                 "Democracy",
                                 "Nuclear power",
                                 "Population",
                                 "GDP per capita",
                                 "Mil. expenditure"),           
           p.auto = FALSE,
           t.auto = FALSE,
           type = "text")
```

# References
